---
title: "SBD2_loan_sample_09"
author: "xy"
date: '2023'
output: html_document
df_print: paged
---

# Inroduction

xy


We call all the libraries that we are going to use and install the packeges when its needed.
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)

libraries = c("readr", "ggplot2", "dlookr", "dplyr", "RColorBrewer", "DescTools", "ROSE", "ggcorrplot", "car", "plotly", "tidyverse", "Boruta", "corrplot", "GGally")

lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})

lapply(libraries, library, quietly = TRUE, character.only = TRUE)
```

We remove the environment and set the seed to make sure that the results gone be the same
```{r}
rm(list=ls())

set.seed(7)
```

We import the csv file "loan_sample_9.csv" and make a copy of it to ensure that we don't mess up the original dataset
```{r setup, include=FALSE, echo=FALSE}
data_loans <- read_csv("loan_sample_9.csv")
#We make a copy from the original dataset and we will work with the copy
data <- data_loans
```


# Descriptive analysis 
## Structure and dimensions of the data set

In the first step we explore the data and run some preliminary descriptive analytics

We start by investigating the structure of the data set.
There are 12 numeric and 5 categorical variables in the dataset. But the numeric variable "Status" with its values "1" and "0" looks like a factor and all the characteristic variables also look like factors.
```{r, echo=FALSE}
head(data)
tail(data)

str(data)
```


# Data quality issues 
## Checking for NAs

In the next step, we using the apply() function to check the presence of NAs in each of the variables included in the dataset.
```{r}
knitr::kable(apply(data, 2, function(x) any(is.na(x))))
```

```{r}
overview <- overview(data)
plot(overview)
```


##Transform and Summerize of the variables

Let's see how many categories the variables have character and summarize the variables.
So we transform the characteristic variables in factors to count the categories and order them. 
```{r}
data$grade = as.factor(data$grade)
data$home_ownership = as.factor(data$home_ownership)
data$verification_status = as.factor(data$verification_status)
data$purpose = as.factor(data$purpose)
data$application_type = as.factor(data$application_type)
data$Status = as.factor(data$Status)

data <- data %>%
  select(order(sapply(., is.factor)),order(sapply(., is.numeric)))
```

```{r}
overview <- overview(data)
plot(overview)
```

The Variable "purpose" (category provided by the borrower for the loan request) ha
In most numerical variables there is a large gap between the minimum and maximum.
For example, "loan-amnt" (amount of the loan applied for by the borrower) has a minimum of 1,000 and a maximum of 40,000, or "revol_bal" (Total credit revolving balance) from 0 to 78,762.
The most people are graded between "B" and "C", in the grades "A" or "B" are similar number of people. The variable "grade" assigned loan grade by the financial service provider.
The most people are in rent or has a mortgage for there home. 3,982 people are home owner.
14,278 people from 40,000 aren't verified.
We notice that in our sample, we have 34,794 persons which have the factor "1" on their loan and we have 5,206 with the value "0".
```{r}
summary(data)
```


## Balance of the target variable  

In the next step, we investigate our target variable. We notice also before in our sample, that we have 5,206 persons which did not default on their loan and we have 34,794 which did default. 
```{r}
PercTable(data$Status)
```
Visualization of the count by plotting a bar plot. 
As we see the data set is highly imbalanced.
```{r}
ggplot(data, aes(x = Status, fill = Status)) +
  geom_bar() +
  ylab("Count") +
  xlab("Status of the loan")
```
In the next step, we carry-out under sampling. 
```{r}
set.seed(7)
data_original <- data
data_balanced <- ovun.sample(Status ~ ., data=data, method = "under")
data_under <- data.frame(data_balanced[["data"]])
```

Let's visualize our changed dataset. 
```{r}
ggplot(data_under, aes(x = Status, fill = Status)) +
  geom_bar() +
  ylab("Count") +
  xlab("Status of the loan")
```

Visualization of the level of the target variable
```{r}
corr_data <- cor(data[1:11])
p_value_data <- cor_pmat(data[1:11])
ggcorrplot(corr_data, type = "lower",
           p.mat = p_value_data,
           outline.col = "white",
           ggtheme = ggplot2::theme_gray,
           colors = c("tomato2", "white", "skyblue2"),
           lab = TRUE)
```


## Cheking for outliers 

We provide a boxplot of the numeric variables in both the original and under-sampled dataset. 
```{r, fig.width=20, fig.height=20}
# Simple visualization of the full data 
boxplot(scale(data[,1:11]), use.cols = TRUE)
```
```{r}
knitr::kable(diagnose_outlier(data_under), caption = "Diagnose Outlier", digits = 2)
```

Visualzation with and without the outliers. 
We note that for the variables "annual_inc" (The self-reported annual income provided by the borrower during registration) the visualization changes considerably and there the median also tends to shift strongly.
```{r}
data_under %>%
  plot_outlier(diagnose_outlier(data_under) %>%
                 filter(outliers_ratio >= 0.5) %>%          # dplyr
                 select(variables) %>%
                 unlist())
```

### Dealing with outliers 

We do winsorizing for dealing with the highest outliers.
```{r}
outlier <- function(x){
    quantiles <- quantile(x, c(.05, .95))
    x[x < quantiles[1]] <- quantiles[1]
    x[x > quantiles[2]] <- quantiles[2]
    x
}

data_new_under <- map_df(data_under[,-c(12:17)], outlier)
cols <- data_under[,c(12:17)]
data_new_under <- cbind(data_new_under, cols)
```


Let's check how the boxplot looks like
```{r, fig.width=20, fig.height=20}
boxplot(scale(data_new_under[,c(1:11)]), use.cols = TRUE)
```

```{r}
for (i in 1:length(data_new_under[,-c(12:17)])) {
  print(ggplot(data_new_under, aes(y = data_new_under[,i], color = Status)) + 
          geom_boxplot() + 
          ylab(names(data_new_under[i])) + 
          theme(axis.title.x=element_blank(),
                axis.text.x=element_blank(),
                axis.ticks.x=element_blank()))
}
```

```{r}
for (i in 1:length(data_new_under[,-c(12:17)])) {
  print(ggplot(data_new_under, 
               aes(x = data_new_under[,i],
                   fill = Status)) +
          geom_density(alpha = 0.2) +
          xlab(names(data_new_under[i])) +
          ylab("Density"))
}

```

```{r, echo=FALSE}
data_new_under$Status <- as.factor(data_new_under$Status)
boruta_output <- Boruta(Status~., data = data_new_under, doTrace=2)
```


Next, we extract and print the significant attributes. 
```{r}
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
```

Next, we visualize the results. 
```{r, fig.width=20, fig.height=20}
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance") 
```

```{r}
correlations = cor(data_new_under[-c(12:17)])
corrplot(correlations) 
```

```{r}
p_value_mat <- cor_pmat(data_new_under[,-c(12:17)])
p1 <- ggcorrplot(correlations, type = "lower", p.mat = p_value_mat) 

ggplotly(p1, tooltip = c("x", "y"))
```


```{r, fig.width=20, fig.height=20}
ggpairs(data[, c("loan_amnt", "int_rate", "annual_inc", "dti", "total_acc", "total_rec_int", "tot_cur_bal")], 
        aes(color = as.factor(data$Status)))
```

























