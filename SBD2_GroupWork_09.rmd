---
title: "SBD2_loan_sample_09"
author: "Ambrosioni Hélène, Sivakolunthu Nerome, Kuster Dario, Pagliarin Larissa"
date: '2023'
output: html_document
df_print: paged
---

# Inroduction

> The following document provides an overview and analysis of a loan decision model developed by Ambrosioni Hélène, Sivakolunthu Nerome, Kuster Dario, and Pagliarin Larissa, specifically focusing on thr exploration, preprocessing, model training, and ethical considerations.

## Exploration and Preprocessing

> The initial steps involve data exploration and preprocessing to understand the structure and characteristics of the dataset.

## Descriptive Analysis
 
> 


***




## Prepare workplace

```{r include=FALSE, echo=FALSE}
rm(list=ls())

set.seed(7)
```

### Install libraries

```{r results='hide', warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

libraries = c("readr", "ggplot2", "dlookr", "dplyr", "RColorBrewer", "DescTools", "ROSE", "ggcorrplot", "car", "plotly", "tidyverse", "corrplot", "GGally", "gridExtra","caret", "ROCR", "outliers")

lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})

lapply(libraries, library, quietly = TRUE, character.only = TRUE)
```



### Read data

> We import the csv file "loan_sample_9.csv" and make a copy of it to ensure that we don't mess up the original dataset.

```{r}
data_loans <- read_csv("loan_sample_9.csv")
data <- data_loans
```
***

## Descriptive analysis 

### Check the data

> In the first step we explore the data. We start by investigating the structure of the data set.
There are 12 numeric and 5 categorical variables in the dataset. But the numeric variable "Status" with its values "1" and "0" looks like a factor and all the characteristic variables also look like factors.

```{r, echo=FALSE}
head(data)
tail(data)
str(data)
```
***

### Data quality issues - Checking for NAs

> We check the presence of NAs in each of the variables included in the dataset.
There are no NAs values in this dataset.

```{r}
knitr::kable(apply(data, 2, function(x) any(is.na(x))))
```
***

### What data types are included in the data set?

> Now we have 12 numeric and 5 character variables.

```{r}
overview <- overview(data)
plot(overview)
```
***

### Transform some variables

> We transform the characteristic variables in factors to count the categories and order them.

```{r}
data$grade = as.factor(data$grade)
data$home_ownership = as.factor(data$home_ownership)
data$verification_status = as.factor(data$verification_status)
data$purpose = as.factor(data$purpose)
data$application_type = as.factor(data$application_type)
data$Status = as.factor(data$Status)

data <- data %>%
  select(order(sapply(., is.factor)),order(sapply(., is.numeric)))
```

```{r}
overview <- overview(data)
plot(overview)
```
***

### Summary of variables

#### Nummeric Variables

> In most numerical variables there is a large gap between the minimum and maximum.
<br>
For example, "loan-amnt" (amount of the loan applied for by the borrower) has a minimum of 1,000 and a maximum of 40,000, or "revol_bal" (Total credit revolving balance) from USD 0 to USD 78,762.
<br>
<br>
The average interest rate "int_rate" is around 12.63%, with values between 5.31% and 27.49%.
<br>
<br>
The annual income "annual_inc" of borrowers varies greatly, with an average of around USD 63,277.
<br>
There are outliers with very high annual salaries.
<br>
<br>
There are borrowers with a dti of 0, which could indicate low indebtedness.


#### Variable "purpose"

> The Variable "purpose" (category provided by the borrower for the loan request) has many categories. They contain the name of the type of loan, except for one group. This group is labeled as "other" and contains 2,283 values. Most loans are used for debt consolidation and credit cards.


#### Variable "grade"

> The most people are graded between "B" and "C", in the grades "A" or "B" are similar number of people. The variable "grade" assigned loan grade by the financial service provider.


#### Variable "home_ownership"

> The most people are in rent or has a mortgage for there home. 3,982 people are home owner.
14,278 people from 40,000 aren't verified.


#### Variable "verification_status"

> We see that 14,278 people are not verifide from 40,000 people. 16,129 are source verifide.


#### Variable "application_type"

> Only 530 joined via App from 40,000 people in the System.


#### Variable "Status"

> The target variable "Status" is unbalanced, as there are more loans without default (status 0 = 34,794 persons) than with default (status 1 = 5,206).

```{r}
summary(data)
```
***

## Balance of the target variable  

> In the next step, we investigate our target variable "Status". We notice also before in our sample, that we have 5,206 persons which did not default on their loan and we have 34,794 persons which did default. 
<br>
<br>
As we can see in the visualization the data set is highly imbalanced.

```{r}
ggplot(data, aes(x = Status, fill = Status)) +
  geom_bar() +
  ylab("Count") +
  xlab("Status of the loan")
```

```{r}
PercTable(data$Status)
```
***


## Distribution of the numeric variable

> The visualizations are all skewed to the right. However, the variable "dti" is almost bell-shaped.
<br>
Almost all numerical variables show many outliers on the visualization. The variable with the best visibility is the variable "annual_inc". 
<br>
The variable "total_acc" has a moderate number of outliers, "open_acc" and "revol_util" have few outliers.

```{r fig.width=15, fig.height=5, echo=FALSE}

create_numeric_plots <- function(data, variable) {
  
  # Histogramm
  hist_plot <- ggplot(data, aes(x = !!sym(variable))) +
    geom_histogram(fill = "#00CED1", color = "white", bins = 30) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(size = 20)) 

  # Boxplot
  box_plot <- ggplot(data, aes(y = !!sym(variable))) +
    geom_boxplot(fill = "#00CED1", color = "black") +
    labs(title = paste("Boxplot of", variable), y = variable) +
    theme_minimal() +
    theme(plot.title = element_text(size = 20))  

  # Kernel Density Plot
  density_plot <- ggplot(data, aes(x = !!sym(variable))) +
    geom_density(fill = "#00CED1", color = "white") +
    labs(title = paste("Kernel Density Plot of", variable), x = variable, y = "Density") +
    theme_minimal() +
    theme(plot.title = element_text(size = 20)) 

  # List of Plots
  return(list(hist_plot, box_plot, density_plot))
}

numeric_variables <- c("loan_amnt", "int_rate", "annual_inc", "dti", "open_acc", "revol_bal",
                        "revol_util", "total_acc", "total_rec_int", "tot_cur_bal", "total_rev_hi_lim")

for (variable in numeric_variables) {
  plots <- create_numeric_plots(data, variable)
  grid.arrange(grobs = plots, ncol = 3)
}

```



***


## Cheking for outliers 

> Here we see the box plots next to each other on one visualization. 
<br>
This view confirms the results of the previous visualization. 
 
```{r, fig.width=20, fig.height=20, echo=FALSE}
# Simple visualization of the full data 
boxplot(scale(data[,1:11]), use.cols = TRUE)
```



***

### Analysis of outliers

> * The variable **"loan_amnt"** has a moderate number of outliers, which could indicate that there are loans with unusually high amounts.
* The variable **"int_rate"** shows some outliers with higher interest rates, which may indicate special loan conditions.
* The variable **"annual_inc"** shows some outliers with very high annual salaries, which could indicate individuals with exceptionally high incomes.
* The variable **"dti"** shows only a few outliers, which could indicate unusually high debt-to-income ratios for some applicants.
* The variable **"open_acc"** shows some outliers, which could indicate borrowers with an unusually high number of open credit accounts.
* The variable **"revol_bal"** shows many outliers with high revolving balance amounts, which could indicate borrowers with large credit card balances.
* The variable **"revol_util"** has only one outlier. This outlier could indicate an unusually high revolving utilization rate for a borrower.
* The variable **"total_acc"** shows some outliers, which could indicate borrowers with an unusually large number of total credit accounts.
* The variable **"total_rec_int"** has many outliers with high total interest payments, which could indicate special loan conditions or exceptionally high interest rates, as we have already seen with the variable "int_rate".
* The variable **"tot_cur_bal"** shows some outliers with high total balances, which could indicate borrowers with significant loan account balances.
* The variable **"total_rev_hi_lim"** shows many outliers with high total credit limits, which could indicate borrowers with large credit limits.


```{r}
knitr::kable(diagnose_outlier(data), caption = "Diagnose Outlier", digits = 2)
```
***





### Visualzation with and without the outliers. 

> We note that for the variables "annual_inc", "revol_bal" and "total_rev_hi_lim" the visualization changes considerably and there the median also tends to shift.
<br>
The distribution of the variable "loan_amnt" would fluctuate somewhat more. 
<br>
The other variables would not change much.

```{r, echo=FALSE}
data %>%
  plot_outlier(diagnose_outlier(data) %>%
                 filter(outliers_ratio >= 0.5) %>%          # dplyr
                 select(variables) %>%
                 unlist())
```



***



### Dealing with outliers 


> The decision to use the winsorizing method was made to improve the robustness of the data and to minimize possible biases due to extremely high or low values in the target variable. The specific code section uses the quantile method to calculate the bounds for winsorizing.

```{r}
outlier <- function(x, trim = 0.05) {
  q <- quantile(x, c(trim, 1 - trim), na.rm = TRUE)
  x[x < q[1]] <- q[1]
  x[x > q[2]] <- q[2]
  return(x)
}


data_new_under <- map_df(data[,-c(12:17)], outlier)
cols <- data[,c(12:17)]
data_new_under <- cbind(data_new_under, cols)
```

```{r, fig.width=20, fig.height=20}
boxplot(scale(data_new_under[,c(1:11)]), use.cols = TRUE)
```
***

> Almost none of the variables still show outliers after adjustment. 
<br>
Only the variable "total_rec_int" still shows a high total interest payment, which could indicate special credit conditions or exceptionally high interest rates.
<br> 
We therefore assume that this corresponds to the representable truth and will not be processed further.

```{r}
knitr::kable(diagnose_outlier(data_new_under), caption = "Diagnose Outlier", digits = 2)
```
***


## Compare "Default" and "Non-Default" groups

> * **"loan_amnt":** The average loan amount for the "Default" group is slightly higher than for the "Non-Default" group.
 * **"int_rate":** The average interest rate for the "Default" group is higher than for the "Non-Default" group.
* **"annual_inc":** The average annual income for the "Default" group is lower compared to the "Non-Default" group.
* **"dti":** The average ratio of debt to income is higher for the "Default" group than for the "Non-Default" group.
* **"open_acc":** The average number of open credit lines is similar for both groups.
* **"revol_bal":** The average revolving loan amount for the "Default" group is lower compared to the "Non-Default" group.
* **"revol_util":** The average revolving credit utilization ratio is higher for the "Default" group than for the "Non-Default" group.
* **"total_acc":** The average total number of credit lines is similar for both groups.
* **"total_rec_int":** The average total interest on loans for the "Default" group is higher than for the "Non-Default" group.
* **"tot_cur_bal":** The average total balance of current loans for the "Default" group is lower than for the "Non-Default" group.
* **"total_rev_hi_lim":** The average total credit limit for the "Default" group is lower than for the "Non-Default" group.

```{r}
summary_data <- data.frame()

for (variable in names(data_new_under[, -c(12:17)])) {
  
  # mean & sd
  mean_default <- mean(data_new_under[data_new_under$Status == 1, variable], na.rm = TRUE)
  sd_default <- sd(data_new_under[data_new_under$Status == 1, variable], na.rm = TRUE)
  
  mean_non_default <- mean(data_new_under[data_new_under$Status == 0, variable], na.rm = TRUE)
  sd_non_default <- sd(data_new_under[data_new_under$Status == 0, variable], na.rm = TRUE)
  
  summary_data <- rbind(summary_data, data.frame(
    Variable = variable,
    Mean_Default = mean_default,
    SD_Default = sd_default,
    Mean_Non_Default = mean_non_default,
    SD_Non_Default = sd_non_default
  ))
}

knitr::kable(summary_data, caption = "Default and Non-Default Groups", digits = 2)
```


### Visualization

```{r fig.height=20, fig.width=20}
boxplots <- list()
for (i in 1:length(data_new_under[,-c(12:17)])) {
  boxplot <- ggplot(data_new_under, aes(y = data_new_under[,i], color = Status)) + 
    geom_boxplot() + 
    ylab(names(data_new_under[i])) + 
    theme(axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          text = element_text(size = 40)) 
  boxplots[[i]] <- boxplot
}

grid.arrange(grobs = boxplots, ncol = 3)
```


```{r fig.width=20, fig.height=20}
density_plots <- list()
for (i in 1:length(data_new_under[,-c(12:17)])) {
  density_plot <- ggplot(data_new_under, 
                         aes(x = data_new_under[,i],
                             fill = Status)) +
    geom_density(alpha = 0.2) +
    xlab(names(data_new_under[i])) +
    ylab("Density") +
    theme(text = element_text(size = 40))
  density_plots[[i]] <- density_plot
}

grid.arrange(grobs = density_plots, ncol = 3)
```



***


## Associations between the categorical variables and the target feature

> * **"grade":** the "non-default" values are highest in category B and the highest "default" values are only slightly higher in category D.
* **"home_ownership":** the "non-default" values are almost the same in the mortage and rent categories and the highest "default" values are in the rent category.
* **"verification_status":** the "non-default" values are slightly higher in the source verified category than in the not verified category and the highest "default" values are in the source verified category.
* **"purpose":** the "non-default" and "default" values are highest in the debt consolidation category.
* **"application_type":** the "non-default" and "default" values are highest in the individual category.
* **"Status":** here you can again see the unbalanced distribution between "Default" and "Non-Default".

```{r fig.width=20, fig.height=20}
create_category_plots <- function(data, variable) {
  bar_plot <- ggplot(data, aes(x = factor(!!sym(variable)), fill = Status)) +
    geom_bar(position = "stack") +
    labs(title = paste("Barplot of", variable), x = variable, y = "Count") +
    theme_minimal() +
    theme(
      text = element_text(size = 40),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
  return(bar_plot)
}

category_variables <- colnames(data_new_under)[12:17]

plots_list <- lapply(category_variables, function(variable) {
  create_category_plots(data_new_under, variable)
})

grid.arrange(grobs = plots_list, ncol = 3)

```


***



## Correlations between the numerical features

> **Strong positive correlations:**
<br>
* Variables "loan_amnt" and "total_rec_int" have a strong positive correlation of 0.69.
* Variables "revol_bal" and "total_rev_hi_lim" also have a strong positive correlation of 0.7.
* Variables "total_acc" and "open_acc" have a strong positive correlation of 0.63.
<br>
<br>
**"loan_amnt" and "total_rec_int"**
<br>
These two concepts are usually not identical. The first refers to the interest payments that have already been made, while the second is the income reported by the borrower himself, which serves as the basis for granting the loan.
<br>
Therefore, we keep both variables.
<br>
<br>
**"revol_bal" and "total_rev_hi_lim"**
<br>
These two values are not identical. The first refers to the actual amount outstanding, while the second indicates the maximum credit limit. However, comparing these values can provide insight into the borrower's credit utilization and credit availability. If the outstanding amount is close to the credit limit, this could indicate a high level of indebtedness.
<br>
Therefore, also here we keep both variables.
<br>
<br>
**"total_acc" and "open_acc"**
<br>
These two values provide information on recent credit activity (number of accounts opened in the last 6 months) and total credit utilization history (total number of credit lines). A high value for the number of open trade lines in the last 6 months could indicate active credit utilization, while the total number of credit lines reflects the overall credit history. 
<br>
Here again, we find it important to keep the difference between the two.

```{r fig.width=8, fig.height=5}
corr_data_new_under <- cor(data_new_under[,-c(12:17)])
p_value_data_new_under <- cor_pmat(data_new_under[,-c(12:17)])
ggcorrplot(corr_data_new_under, type = "lower",
           p.mat = p_value_data_new_under,
           outline.col = "white",
           ggtheme = ggplot2::theme_gray,
           colors = c("tomato2", "white", "skyblue2"),
           lab = TRUE, lab_size = 8 )

```


```{r, echo=FALSE}
correlations = cor(data_new_under[-c(12:17)])
corrplot(correlations, order= "FPC", col = COL2(n=20))
```



***


### Association between the loan amount requested and the annual income of the borrower

> **Color Coding:** 
<br>
Light blue points represent Loan Amount, and blue points represent Annual Income.
<br> 
<br>
**Scatter plot for "loan_amnt":** 
<br>
The red line on the plot is a regression line (trend line) between Loan Amount and Annual Income. It looks like a straight line, suggesting a linear relationship.
<br>
The points tend to follow the trend line closely, it indicates a strong linear relationship.
<br>
<br>
**Scatter plot for "annual_inc":** 
<br>
The points are scattered and don't follow a clear trend, the relationship may be less predictable.
**Conclusion:**
<br>
There's a tendency for one to increase or decrease as the other changes.


```{r}
# Scatter plot for loan_amnt
scatter_loan_amnt <- plot_ly(data_new_under, 
                              x = ~loan_amnt, 
                              y = ~annual_inc, 
                              mode = "markers",
                              type = "scatter", 
                              marker = list(color = "#00CED1", size = 8, opacity = 0.7),
                              showlegend = FALSE) %>%
  add_trace(x = ~loan_amnt, 
            y = ~fitted(lm(annual_inc ~ loan_amnt)),
            mode = "lines",
            type = "scatter",
            line = list(color = "#e74c3c"),
            hoverinfo = "none") %>%
  layout(title = "Scatter Plot of Loan Amount vs. Annual Income",
         xaxis = list(title = "Loan Amount"),
         yaxis = list(title = "Annual Income"))

# Scatter plot for annual_inc
scatter_annual_inc <- plot_ly(data_new_under, 
                              x = ~annual_inc, 
                              y = ~loan_amnt, 
                              mode = "markers",
                              type = "scatter", 
                              marker = list(color = "#3498db", size = 8, opacity = 0.7),
                              showlegend = FALSE) %>%
  add_trace(x = ~annual_inc, 
            y = ~fitted(lm(loan_amnt ~ annual_inc)),
            mode = "lines",
            type = "scatter",
            line = list(color = "#e74c3c"),
            hoverinfo = "none") %>%
  layout(xaxis = list(title = "Annual Income"),
         yaxis = list(title = "Loan Amount"))

# Combine the plots using subplot
subplot(scatter_loan_amnt, scatter_annual_inc, nrows = 2)

```


***

## Balancing the target variables

> In the next step, we carry-out under sampling and visualizate it again.
<br>
<br>
Balancing the data set is necessary to ensure that the model is not influenced by an excessive presence of one class over the other. Models can tend to focus on the dominant class and ignore the minority class if the data set is not balanced. Balancing ensures that both classes are equally represented, which can lead to a more balanced model.

```{r}
set.seed(7)
data_original <- data
data_balanced <- ovun.sample(Status ~ ., data=data, method = "under")
data_under <- data.frame(data_balanced[["data"]])
```

```{r}
ggplot(data_under, aes(x = Status, fill = Status)) +
  geom_bar() +
  ylab("Count") +
  xlab("Status of the loan")
```





***



## Exercise 2

### Training and testing a logistic classifier

```{r}
set.seed(7)
div <- createDataPartition(y = data_new_under$Status, p = 0.7, list = F)

# Training Sample
data.train <- data_new_under[div,] # 70% here

# Test Sample
data.test <- data_new_under[-div,] # rest of the 30% data goes here
```


***


### Training the classifier

```{r}
fit1 <- glm(Status ~ ., data=data.train,family=binomial())
summary(fit1)
```


***


#### Explanation:

> From the results obtained, we can deduce the following points.
<br>
<br>
**Deviance residuals:**
* The moderate range of deviance residuals (-2.08 to 2.10) suggests a reasonable fit to the model. Smaller residuals would indicate a more precise fit, but these values are acceptable.
<br>
<br>
**Coefficients:**
* Positive coefficients for "loan_amnt" and "int_rate" indicate that higher loan amounts and interest rates are associated with a higher probability of belonging to the positive class.
<br>
<br>
**Significance:**
* Statistically significant predictors include "loan_amnt," "int_rate," "annual_inc," "total_rec_int," "gradeB," and "gradeC," crucial characteristics that influence the model.
Zero and residual deviance:
* The reduction of deviance from null model 10103.3 to residual deviance 9254.7 suggests that the model, explains some of the variability of the response variable.
<br>
<br>
**AIC:**
* The AIC value of 9318.7 is an indicator of model fit and complexity. Although it could be lower, the AIC is still a reasonable value considering the number of predictors.
<br>
Conduct cross-validation to ensure generalizability of the model.
In summary, the model shows promise with significant predictors, but there is room for improvement. Further analysis and refinement can improve its predictive capabilities and overall performance.


***


### Plotting the ROC Curve

```{r}
data.test$fit1_score <- predict(fit1,type='response',data.test)
fit1_pred <- prediction(data.test$fit1_score, data.test$Status)
fit1_roc <- performance(fit1_pred, "tpr", "fpr")
plot(fit1_roc, lwd=1, colorize = TRUE, main = "Fit1: Logit - ROC Curve")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1, lty=3)
```



***



#### Explanation

>Through the ROC (Receiver Operating Characteristic) curve, we can evaluate the performance of the classification algorithm.
There are several aspects that we can identify and comment on.
<br>
The shows the relationship between the true positive rate (sensitivity) and the false positive rate (1 - specificity) for different thresholds. The true positive rate is shown on the Y-axis and the false positive rate on the X-axis.
The diagonal line represents a random rate classifier. A good classifier is above this line, which means it achieves a higher true positive rate than false positive rate for different thresholds.
On the right we have the color scale which represents the threshold at which the corresponding rate is reached. The red areas represent higher thresholds and the blue areas lower thresholds.
<br>
In our case the curve appears to be well above the diagonal, indicating a better classifier than a random guess. The color scale can be useful to see how thresholds affect evaluation metrics.


***



### visualizing the Precision/Recall Curve

```{r}
fit1_precision <- performance(fit1_pred, measure = "prec", x.measure = "rec")
plot(fit1_precision, main="Fit1: Logit - Precision vs Recall")
```



***


#### Explanation:

> With the precision recall curve we can evaluate the classification model used and understand whether the classes are unequally distributed or not.
<br>
<br>
In the graph, the x and y axes are called recall and precision respectively:
<br>
**Recall (X-axis):** Percentage of actual positive cases that were recognized as positive. Recall is a measure of how many of the actual positive cases the model correctly identified.
<br>
**Precision (Y-axis):** Proportion of relevant instances among instances classified as positive. Precision is a measure of how many of the cases classified as positive are actually positive.
<br>
<br>
The curve in the graph shows the trade-off between precision and recall for different thresholds. Perfect classification would produce a curve at the top right of the graph where both precision and recall are 1.
In this case, precision starts to be high when recall is low. This means that the model is very selective when it decides to classify an instance as positive. As recall increases (the model tries to capture more true positive cases), precision decreases. This is a typical trade-off, as it is often difficult to achieve high precision and high recall at the same time.
Since the curve is directed upwards in the right corner, it can be deduced that there is high precision and recall.


***



### Confusion Matrix

```{r}
confusionMatrix(as.factor(round(data.test$fit1_score)), data.test$Status)
```



***



#### Explanation:

> **Confusion Matrix**
<br>
* It correctly identifies 64.19% of instances (Accuracy) with 62.65% sensitivity (True Positive Rate) and 65.73% specificity (True Negative Rate).
Kappa Statistic
* The Kappa value of 0.2838 indicates fair agreement beyond random chance.
Positive Predictive Value (Precision):
* Precision is at 64.64%, meaning that when the model predicts the positive class, it is correct 64.64% of the time.
Balanced Accuracy:
* The balanced accuracy is 64.19%, reflecting a balance between sensitivity and specificity.
Prevalence and Detection Rate:
* The prevalence of the positive class is 50%, and the model detects it in 31.33% of cases.
Mcnemar's Test
* McNemar's test does not show a significant difference in errors between predictions.
In conclusion, the model demonstrates moderate performance, but there is room for improvement.


***

### Computing the predictive utility of the model through the area under the curve AUC value

```{r}
fit1_auc <- performance(fit1_pred, measure = "auc")
cat("AUC: ",fit1_auc@y.values[[1]]*100)
```



***



#### Explanation:

> The AUC-Value of 70.46687 falls in to the fair discrimination range. While it suggests some ability of our model to distinguish between the two classes, there is definelty room for improvement. It could be valuable to compare our AUC-Value to that of other models to gain further context regarding our model's performance.


***




## Exercise 3

### Improve pre-processing of data

#### Variables

> **Loan utilization ratio:**
<br>
This ratio could indicate how much of the available loan has already been used.

```{r}
summary(data$loan_amnt / data$total_rev_hi_lim)
```


***


> **Income to loan ratio:**
<br>
This could indicate how well the borrower is able to repay the loan, based on their income.

```{r}
summary(data$annual_inc / data$loan_amnt)
```



***



> **Risk categories for the debt-to-income (DTI):**
<br>
A new categorical variable that categorizes debt-to-income (dti) into different risk categories. For example, low, medium and high risk based on certain thresholds.

```{r}
summary(cut(data$dti, breaks = c(-Inf, 15, 25, Inf), labels = c("Low Risk", "Medium Risk", "High Risk")))
```



***



#### Outliers

> **Removing Outliers:**
<br>
Complete removal of outliers can lead to a loss of valuable information. If outliers are influential or carry meaningful insights, removing them might distort the overall understanding of the data.
<br>
<br>
**Data Transformation (e.g., Log Transformation):**
<br>
Transforming the entire dataset might not be appropriate if the distribution is heavily skewed. Additionally, transforming the data can make interpretation challenging.
<br>
<br>
**Imputation:**
<br>
Imputing outlier values with central tendencies (mean, median) or other imputation methods may introduce bias, especially if outliers are indicative of important patterns or events. It might not accurately represent the true underlying data structure.
<br>
<br>
**Clipping:**
<br>
Clipping involves capping extreme values at a predefined threshold. This method can lead to a loss of information, as it essentially treats all extreme values beyond the threshold as identical, ignoring potential differences among them.
<br>
<br>
**Data Binning:**
<br>
Binning involves grouping continuous data into discrete intervals. This can lead to information loss and might not be suitable if the goal is to retain the granularity of the data.
<br>
<br>
**Model-based Approaches:**
<br>
Ignoring or downplaying the existence of outliers in model-based approaches would have been too weak an intervention.



***





## Exercise 4

### Question 1

> What challenges in making credit decisions would a company face if it were to use our model in its day-to-day business?
<br>
These challenges are captured in the four common ethical issues in the context of creating value from data:
<br>
<br>
**Privacy and data security**
<br>
* Collecting and using various financial and personal variables (e.g., "loan_amnt", "int_rate", "annual_inc") for credit decisions requires a strong privacy framework for used customer data. Ensuring encryption, secure storage and compliance with privacy regulations are critical, considering the sensitive nature of financial information.
<br>
<br>
**Algorithmic bias and fairness**
<br>
* The model coefficients reveal that some variables, such as “grade B” and “grade C”, have a significant impact on the predictions. It is essential to carefully examine these variables for possible biases, ensuring that credit decisions are fair and impartial across different grades and demographic groups.
<br>
<br>
**Accountability and Accountability**
<br>
* Model performance parameters, including accuracy and sensitivity, provide a basis for evaluating its effectiveness. Establishing accountability for model results is critical, especially with significant predictors like “loan_amnt” and “int_rate.” Transparent communication about how decisions are made is essential for accountability.
<br>
<br>
**Impact on the workforce**
* Implementing the credit decision model may impact the workforce involved in manual credit assessments. Workforce implications, including potential job role changes, should be considered. Ethical considerations involve transparent communication about these changes and efforts to mitigate any negative impacts on the workforce.
<br>
<br>
In conclusion, while the logistic regression model shows promise in predicting credit decisions, addressing ethical issues requires a comprehensive approach. Ensure rigorous data privacy measures, continually evaluate and mitigate algorithmic bias, establish accountability for model results, and consider social impact on the workforce. Engaging in ongoing ethical discussions and staying attuned to the implications of model decisions will contribute to responsible and ethical implementation in daily business operations.


***


### Question 2

> Companies can overcome or mitigate the problems and difficulties described above associated with implementing predictive models, particularly in credit decision making
In the following way: 
<br>
<br>
**Data Privacy & Security:** Implement Robust Security Measures
<br>
* Employ encryption and secure storage protocols to protect sensitive data.
Adopt anonymization and aggregation techniques to minimize the exposure of individual details.
Ensure compliance with data protection regulations and obtain explicit consent from individuals for data usage.
<br>
<br>
**Algorithmic Bias & Fairness:** Continuous Monitoring and Fairness Audits
<br>
* Regularly monitor and assess model predictions for biases.
Conduct fairness audits, particularly focusing on variables with significant impact.
Adjust the model as needed to ensure fairness across different demographic groups.
<br>
<br>
**Accountability & Responsibility:** Establish Clear Accountability and Transparency
<br>
*Clearly define roles and responsibilities for individuals involved in model development and deployment.
Maintain transparent documentation of the model's decision-making process.
Establish mechanisms for accountability and redress in case of errors or unintended consequences.
<br>
<br>
Impact on the Workforce: Responsible Workforce Management
* Provide training and upskilling opportunities for employees affected by automation.
Communicate transparently about changes in job roles or responsibilities.
Consider the societal impact and contribute to initiatives that support workforce development in the face of technological advancements.
<br>
<br>
By adopting these strategies, companies can navigate the ethical challenges associated with deploying predictive models for credit decisions, fostering responsible and transparent practices in their daily business operations. Regular reassessment and adaptation to evolving ethical standards and regulations are essential for continued ethical performance



***

































